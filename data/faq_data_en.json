{
  "faq": [
    {
      "question": "What is AI FAQ Bot?",
      "answer": "AI FAQ Bot is a FastAPI application that provides an API for managing and querying FAQs using AI."
    },
    {
      "question": "How do I use the API?",
      "answer": "You can use the API by sending requests to the endpoints defined in the documentation. Check /docs for the Swagger UI for an interactive experience."
    },
    {
      "question": "What technologies are used?",
      "answer": "The bot is built with Python, FastAPI, and uses OpenAI's APIs for natural language processing tasks like summarization and embeddings."
    },
    {
      "question": "How does the semantic search work?",
      "answer": "Semantic search works by converting questions into numerical representations (embeddings) and finding the closest matches based on cosine similarity. This allows finding answers to questions that are semantically similar, not just keyword matches."
    },
    {
      "question": "Where is the FAQ data stored?",
      "answer": "The FAQ data is stored in a JSON file located at `data/faq_data.json`."
    },
    {
      "question": "How do I run the application?",
      "answer": "You can run the application locally using `uvicorn app.main:app --reload`. Make sure you have installed all the dependencies from `requirements.txt`."
    },
    {
      "question": "How can I run the project with Docker?",
      "answer": "You can use the provided `Dockerfile` and `docker-compose.yml` to build and run the application in a containerized environment. Simply run `docker-compose up`."
    },
    {
      "question": "What are embeddings?",
      "answer": "Embeddings are vector representations of text, where words and sentences with similar meanings are placed closer together in a multi-dimensional space. We use them to understand the semantic meaning of questions."
    },
    {
      "question": "How do I regenerate the embeddings for the FAQ?",
      "answer": "The embeddings are generated automatically if the `faq_embeddings.pkl` file is not found. To force regeneration, you can delete this file and restart the application. An API endpoint for this is also planned."
    },
    {
      "question": "What is the purpose of the `requirements.txt` file?",
      "answer": "The `requirements.txt` file lists all the Python packages that the project depends on. You can install them all by running `pip install -r requirements.txt`."
    },
    {
      "question": "How is the OpenAI API key managed?",
      "answer": "The OpenAI API key should be set as an environment variable named `OPENAI_API_KEY`. The application loads this variable to configure the OpenAI client. It is not stored in the code."
    },
    {
      "question": "Can I use a different embedding model?",
      "answer": "Yes, you can change the model by modifying the `model` parameter in the `get_embeddings` function call within the `openai_services.py` file."
    },
    {
      "question": "How can I contribute to the project?",
      "answer": "Contributions are welcome! You can contribute by forking the repository, creating a new branch for your feature or bug fix, and submitting a pull request. Please follow the existing code style."
    },
    {
      "question": "What is the license of this project?",
      "answer": "This project is licensed under the MIT License. You can find the full license text in the `LICENSE` file."
    },
    {
      "question": "How do I get a summary of a YouTube video?",
      "answer": "You can use the `/youtube/summary` endpoint. Send a POST request with a JSON body containing the `video_url` to get a structured summary of the video's transcript."
    },
    {
      "question": "What should I do if the semantic search returns irrelevant results?",
      "answer": "If the search results are not relevant, the underlying FAQ data may not have the right information. Consider adding more relevant Q&A pairs to `faq_data.json` and regenerating the embeddings. You could also experiment with different embedding models."
    },
    {
      "question": "Is there API authentication?",
      "answer": "Currently, the API is open for simplicity. For production environments, implementing an authentication layer using FastAPI's security utilities (like OAuth2 or API Keys) is highly recommended."
    },
    {
      "question": "How are application logs managed?",
      "answer": "The application is configured to log events to both the console and a file in the `logs/` directory. The logging configuration can be adjusted in `app/config/logging.py`."
    },
    {
      "question": "What is the main web framework used in this project?",
      "answer": "The project is built using FastAPI, a modern, fast web framework for building APIs with Python."
    },
    {
      "question": "What tool is used for testing?",
      "answer": "The project uses Pytest, a powerful and popular testing framework for Python."
    },
    {
      "question": "How is the application served during development?",
      "answer": "Uvicorn, an ASGI server, is used to run the application, especially with the `--reload` flag for a better development experience."
    },
    {
      "question": "Which tools ensure code quality?",
      "answer": "The project uses Black for consistent code formatting and Flake8 for linting to catch style issues and errors."
    },
    {
      "question": "What are the prerequisites for setting up the project?",
      "answer": "You need to have Python 3.10+ and Git installed on your system."
    },
    {
      "question": "What is the command to start the application locally?",
      "answer": "You can start the application by running `uvicorn app.main:app --reload --host 0.0.0.0 --port 8000`."
    },
    {
      "question": "What are the guidelines for contributing to the project?",
      "answer": "Contributors should follow PEP 8 style, add tests for new features, update documentation as needed, and use meaningful commit messages."
    },
    {
      "question": "Where can I find help or report an issue?",
      "answer": "You can check the GitHub Issues page. If your problem is not listed, you can create a new issue with detailed information."
    },
    {
      "question": "How can I use my own FAQ data with the API?",
      "answer": "You can provide a URL to your own `faq_data.json` file via the `faq_url` parameter in the `/api/v1/faq/search` endpoint. The API will dynamically load and use your data."
    },
    {
      "question": "What happens if I provide an invalid URL for the FAQ data?",
      "answer": "The API includes robust error handling. If the URL is invalid, unreachable, or the content is not valid JSON, the API will return a specific HTTP error (e.g., 400 Bad Request) with a descriptive message."
    },
    {
      "question": "How are the embeddings cached?",
      "answer": "When you provide a `faq_url`, the service generates embeddings for that FAQ and caches them in memory. Subsequent requests using the same URL will be much faster as they will use the cached embeddings."
    },
    {
      "question": "What is the default embedding model?",
      "answer": "The service uses OpenAI's `text-embedding-3-small` model by default, which offers a good balance of performance and cost. This can be configured in the `openai_services.py` file."
    },
    {
      "question": "What is the purpose of the `app/schemas` directory?",
      "answer": "The `app/schemas` directory contains Pydantic models that define the data shapes for API requests and responses, ensuring data validation and clear API contracts."
    },
    {
      "question": "What is the difference between the `main` and `standalone` branches?",
      "answer": "The `main` branch contains the API that can load FAQs from any URL. The `standalone` branch is designed to work with a built-in, local `faq_data.json` file, making it a self-contained application without the dynamic loading feature."
    },
    {
      "question": "How can I change the application's default port?",
      "answer": "You can change the port by modifying the `uvicorn` command. For example, to run on port 8080, use: `uvicorn app.main:app --reload --port 8080`."
    }
  ]
}
